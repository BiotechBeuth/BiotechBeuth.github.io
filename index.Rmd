---
title: "R Intro für Biotechnologen"
author: "U. Rieger"
output: 
  html_document: 
    fig_caption: yes
    toc: yes
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Laden benötigter Pakete

In diesem Intro werden wir mit dem Paket Biotech arbeiten, dieses installieren wir mit:
```{r , eval = F}
devtools::install_github("https://github.com/Utzi1/Biotech")
```
Installieren müssen wir es nur ein Mal, danach jedoch müssen wir in jedem Skript, in welchem es zum Einsatz kommt, auf seine Existenz verweisen, wir müssen es "laden":
```{r message=FALSE, warning=FALSE, paged.print=FALSE}
library(Biotech)

# Wir laden auch tidverse, dieses Paket enthält eine Menge
# nützlicher Funktionen
library(tidyverse)
```
# Eine Konzentrationsbestimmung

## Rohdatenverarbeitung

Ihr habt im Labor den Bradford-Assay durchgeführt und mit Rinderserumalbumin eine Standardreihe aufgenommen, dazu wurden zu jeder Verdünnung vier technische Replikate angefertigt und deren Absorption gemäß der Vorschrift gemessen.
Die Ergebnisse der Messung lauten:
```{r echo=FALSE}
Std <- tibble(
  mes.1 = c(0.031,	0.092,	0.191,	0.278,	0.332, 0.363),
  mes.2 = c(0.04, 0.103, 0.201, 0.279, 0.348, 0.36),
  mes.3 = c(0.009, 0.077, 0.166, 0.205, 0.25, 0.397), 
  mes.4 = c(0.007, 0.084, 0.166, 0.205, 0.353, 0.371),
  )
conc <- seq(
            # die geringste Konzentration
            from = 0,
            # die Höchste Konzentration
            to = 100,
            # die Länge
            length.out = 
                # diese muss der Anzahl der Messungen entsprechen
                length(Std$mes.1)
            )
Std$"conc" <- conc
pander::pander(Std)
```

Diese fassen wir gleich als tibble zusammen:
```{r}
Std <- tibble(
  mes.1 = c(0.031,	0.092,	0.191,	0.278,	0.332, 0.363),
  mes.2 = c(0.04, 0.103, 0.201, 0.279, 0.348, 0.36),
  mes.3 = c(0.009, 0.077, 0.166, 0.205, 0.25, 0.397), 
  mes.4 = c(0.007, 0.084, 0.166, 0.205, 0.353, 0.371),
  )
```
Zusätzlich dazu brauchen wir eine Vector, welcher Information über die Konzentration des BSA in den angesetzten Standards (in $\frac{\mu g}{ml}$) bereithält:
```{r}
conc <- seq(
            # die geringste Konzentration
            from = 0,
            # die Höchste Konzentration
            to = 100,
            # die Länge
            length.out = 
                # diese muss der Anzahl der Messungen entsprechen
                length(Std$mes.1)
            )
```

Die Länge (also Anzahl der einzelnen Werte muss der Anzahl der Standards entsprechen) wird über das Argument length.out gesteuert.
Als Nächstes berechnen wir das arithmetische Mittel der technischen Replikate:
```{r}
Std.mean <- rowMeans(Std)
```

## Errechnen eines Linearen Modell

Damit haben wir nun alles um ein lineares Modell vom Typ $y = m \cdot x + b$ zu errechnen und zu plotten, dies geht recht leicht:
```{r message=FALSE, warning=FALSE, paged.print=TRUE}
# Berechnen des Modells
LinMod(abs = Std.mean, conc = conc) %>%
    # Überführen des Modells in eine schöne Tabelle
  pander::pander()

# Plotten des Modells
plot_regression(abs = Std.mean, conc = conc)
```

## Konzentrationsbestimmung der Proben

Nach dem selben Verfahren wie die Standardreihe wurde auch mit Proben unbekannter Konzentration verfahren, für diese wurden folgende Absorptionswerte gemessen:
```{r message=FALSE, warning=FALSE}
# die gemessenen Werte:
mes.1 <- c(0.185, 0.245, 0.399, 0.429, 0.448, 0.431)

# definieren des Verdünnungsfaktor
FV <- c(80, 80, 40, 40, 20, 20)

# Hieraus berechnen wir dann direkt die Konzentrationen:
conc.mes <- 
    conc_eval(abs_P = mes.1, abs_std = Std.mean, conc_std = conc)

conc.rea <- 
    conc.mes * FV

# Erzeugen einer Ausgabe
print(conc.rea)
```
Bei genauerer Betrachtung fällt auf, dass die Werte, welche zu den geringeren Verdünnungen gehören viel geringere Konzentrationen aufweisen, als jene der schwachen Verdünnungen.
Dies lässt sich damit erklären, dass der Bradford Assay nur innerhalb eines bestimmten linearen Bereichs zuverlässige Ergebnisse liefert.
Dieser liegt in der Regel unterhalb einer Konzentration von $120 \frac{\mu g}{ml}$, ein Vergleich der Messwerte mit den theoretischen Konzentrationen ist dabei hilfreich.
 
# Auswertung einer 96-Well-Platte

Das Paket Biotech enthält Datensätze welche zum Testen und Experimentieren angefügt wurden, zwei davon sind ELISA-Assays wie sie im Immunologischen Praktikum zum Nachweis vom Humanserumalbumin in Urin entstehen.
Um uns zu verdeutlichen wie groß die Absorptionen in welchen Wells waren können wir durch das anfertigen einer Heatmap schnell die gemessenen Daten visualisiert vor Augen führen.
Eine Heatmap ordnet einem Wert eine Farbintensität zu, hierbei kann die räumliche Anordnung leicht berücksichtigt werden.
```{r}
str(HSA1)
```

## Rohdatenaufarbeitung und Plotten

Um nur die Informationen zu bekommen, die wir benötigen werden wir ein paar Transformationsschritte durchführen:
```{r}
daten <- HSA1[,2:13] %>% 
    as.matrix() %>% 
    as.vector()
```
Nun liegen die Messwerte als Vektor in lineare Form vor, diese können wir in einem Grid "fangen", dazu müssen wir dieses Grid erst mal "aufspannen":
```{r}
# y wird durchnummeriert, als charcter
y  <- paste0(seq(1,12))

# x bekommt die erstest acht Buchstaben des Alphabets
x <- LETTERS[1:8]

# erstellen des Grid
grid.1 <- expand.grid(X = x, Y = y)

# füllen des Grid mit den Daten als Abs
grid.1$Abs <- daten

# plotten des Grid
ggplot( data = grid.1, mapping = aes( X, Y, fill = Abs ) )+
    geom_tile()
```

## Definition einer Funktion

Um in Zukunft schneller das selbe machen zu können schreiben wir eine Funktion welche diese Aufgabe übernimmt.
R ist eine funktionale Programmsprache, das bedeutet, dass es für viele Probleme bereits Funktionen gibt.
Dies erleichtert gerade nicht-Programmierern das schreiben von Skripten.
Sollte nun jedoch, wie in unserem Fall, keine Funktion für das Problem zur Hand sein wird diese einfach geschrieben:

```{r}
    # Name:
vis96 <- 
    # die function-Funktion
    function(
             # Die Argumente der Funktion vis96
             HSA.assay) {
    # die eigentliche Funktion
    daten <- HSA.assay[,2:13] %>% 
    as.matrix() %>% 
    as.vector()
    y  <- paste0(seq(1,12))
    # x bekommt die erstest acht Buchstaben des Alphabets
    x <- LETTERS[1:8]
    # erstellen des Grid
    grid.1 <- expand.grid(X = x, Y = y)
    # füllen des Grid mit den Daten als Abs
    grid.1$Abs <- daten
    # plotten des Grid
    vis96 <- ggplot( data = grid.1, mapping = aes( X, Y, fill = Abs ) )+
        geom_tile()
    # Definition der Ausgabe
    return(vis96)
}
```
Wir können diese Funktion nun testen, dazu verwenden wir den zweiten HSA-Assay (HSA2):
```{r}
vis96(HSA.assay = HSA2)
```

Die Vorteil des Verwendens einer Funktion werden im Beispiel klar:

* die Funktion bedeutet weniger Tippen
* sie macht den Code übersichtlicher

Ein weiterer Vorteil ist, dass die Funktion leicht geändert werden kann, wenn nun zum Beispiel eine Änderung in der Methode (Format der Ausgabe) des Assays eingeführt wird kann die Funktion einfach geändert werden.

## Vergleich mit den zu erwartenden Werten 

Das Originalpipettierschema, in hellgrün die Standardreihe, in gelb und hellgelb die Studentenurinproben und die tieferen grün töne markieren die Auftragungspunkten des Patientenurin, gibt uns eine Idee, welche Messwerte wo zu erwarten sind:
![hellgrün die Standardreihe, in gelb und hellgelb die Studentenurinproben und die tieferen Grüntöne markieren die Auftragungspunkten des Patientenurin](pipettierschema.jpg)

So wird klar, dass beim ersten Test (HSA1) dieses Schema richtig angewandt wurde, abhängig von der Konzentration variiert auch der die Intensität der jeweils gemessenen Zelle.
Besonders klar deutlich wird das anhand der Standardreihen sowie den Patientenproben.
Ins Auge fallen die Werte F5 und F6.
Für den 2. Assay können wir einen ähnlichen Zusammenhang feststellen, auch auf diesem ist vor allem die Standardreihe sichtbar.

# Konzentrationsbestimmung für den HSA-Assay

# Rohdatenverarbeitung

Vor Beginn der Berechnung der HSA-Konzentration in den Proben müssen wir den Mittelwert der Standardreihen berechnen, die Herausforderung besteht hierbei darin die passenden Spalten zu selektieren.
Anhand des Pipettierschemas kann nachvollzogen werden, dass die entsprechenden Auftragungen in den Spalten 2 bis 4 liegen.
```{r}
# wo liegen die Werte der Standards
stdr <- HSA1[3:5]  %>% 
    rowMeans()
```
Aus dieser Standardreihe können wir dann wieder, wie bereits vorher geschehen, eine Regression errechnen:
```{r}
# Zuordnung der Konzentrationen
conc <- c(0, 5, 10, 15, 20, 30, 40, 50)

# welche Konzentrationen gibt das Modell für die Standards aus
conc_eval(abs_P = stdr, abs_std = stdr, conc_std = conc)

# Definition einer Funktion
HSA.conc.eval <- function(HSA,
         mes) {
  stdr <- HSA[3:5]  %>%
    rowMeans()
  conc <- c(0, 5, 10, 15, 20, 30, 40, 50)
  eval <- conc_eval(abs_P = mes,
            abs_std = stdr,
            conc_std = conc)
  return(eval)
}

# Testen der Funktion
HSA.conc.eval(HSA1, HSA1[3:5])
```
Wenn wir uns dieses Ergebnis ansehe, fällt auf, dass die Leerwerte negativ sind, das kann aber (real) nicht sein.

## Berücksichtigung des Verdünnungsfaktor

Die Verdünnungsfaktoren sind Bekannt, sie müssen lediglich mit-einberechnet werden.
Man könnte die Funktion zusätzlich erweitern:
```{r}
HSA.conc.eval <- function(HSA,
         mes,
         FV = 1) {
  stdr <- HSA[3:5]  %>%
    rowMeans()
  conc <- c(0, 5, 10, 15, 20, 30, 40, 50)
  eval <- conc_eval(abs_P = mes,
            abs_std = stdr,
            conc_std = conc)
  return(eval * FV)
}

# Testen mit dem zweiten Datensatz
HSA.conc.eval(HSA2, HSA2[3:5])
```
Da nach dem Auftragsschema die Verdünnungsfaktoren auch in den Spalten variieren können müssen wir uns diese noch ein mal genauer ansehen.
```{r}
dat.1 <- tibble(
 "FV1000" = c(rowMeans(HSA2[,6:7]),
              rowMeans(HSA2[1:4, 8:9])
              ),
 "FV5000" = c(rowMeans(HSA2[5:8, 8:9]),
              rowMeans(HSA2[,10:11])
              )
) 
conc.1 <- tibble(
  "aus FV1000" = HSA.conc.eval(HSA2, dat.1$"FV1000", 1000),
  "aus FV5000" =  HSA.conc.eval(HSA2, dat.1$FV5000, 5000)
)
conc.1
```

